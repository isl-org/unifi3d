# @package _global_

# to execute this experiment with single GPU run:
# accelerate launch scripts/acc_train.py experiment=cond_generation_unet.yaml

# For multi-GPU training run:
# accelerate launch scripts/acc_train.py trainer=ddp experiment=cond_generation_unet.yaml

# For faster training debugging with fewer samples on a single GPU:
# accelerate launch scripts/acc_train.py experiment=cond_generation_unet.yaml data.config.num_samples=10

defaults:
  - override /data: dualoctree_shape
  - override /model: diffusion
  - override /net_encode: doctree_vae
  - override /net_denoise: unet
  - override /diffusion_sampler: ddpm
  - override /trainer: default
  - override /logger:
    - aim     # default is null.

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["train", "dualoctree", "diffusion"]

seed: 12345
mixed_precision: "no"
octree_depth: 6
full_depth: 2
experiment_name: text_conditional_diff_dualoctree_vae_unet_car_airplane_chair
categories: 
  - "airplane"
  - "car"
  - "chair"

data:
  train_batch_size: 420
  val_batch_size: 1
  test_batch_size: 1
  data_train:
    dataset:
      num_samples: -1
  data_test:
    dataset:
      num_samples: 1
  data_val:
    dataset:
      num_samples: 1

net_encode:
  ckpt_path: checkpoints/dualoctree_vae_car_airplane_chair.safetensors
  code_channel: 8 # Update this number based on the ckpt it uses.
  add_kl_loss: False

net_denoise:
  dims: 3
  image_size: 4 # 16
  in_channels: ${net_encode.code_channel} # 3
  out_channels: ${net_encode.code_channel} # 3
  model_channels: 192
  num_res_blocks: 2
  attention_resolutions:  [1, 2, 4] #[ 1,2,4 ] # 16, 8, 4
  # note: this isn\t actually the resolution but
  # the downsampling factor, i.e. this corresponds to
  # attention on spatial resolution 8,16,32, as the
  # spatial reolution of the latents is 64 for f4
  channel_mult: [1] # [ 1,2,4,4 ] adding 2 seems to have skip unevenly between w,h,d
  # num_head_channels: 32
  num_heads: 6
  # conditional modes
  text: crossattn
  use_spatial_transformer: true
  context_dim: 512 # can be anything

diffusion_sampler:
  beta_schedule: squaredcos_cap_v2
  clip_sample: False

model:
  encoder_decoder: ${net_encode}
  diff_model: ${net_denoise}
  sampling_scheduler: ${diffusion_sampler}
  optimizer:
    lr: 0.0001 # 0.00001
  scheduler:
    _target_: torch.optim.lr_scheduler.StepLR
    step_size: 100
    gamma: 0.9
  


trainer:
  max_epochs: 3600
  min_epochs: 3600
  log_every_n_iter: 1
  check_val_every_n_epoch: -1
  save_checkpoint_every_n_epoch: 100
  ckpt_num: 3

paths:
  log_dir: ${paths.root_dir}/logs/${experiment_name}
  output_dir: ${paths.log_dir}

test: false
logger: 
  aim: # Should be the same as /logger
    config: 
      loggers: ["metric", "image", "hparams"] # List and type of logging implementations 
      tracked_variables: # The keys should match aim/loggers
        metric: ["loss", "lr"]
        image: ["render_gt", "render_rec"]